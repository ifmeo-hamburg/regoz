{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3068a6a-bb7e-412f-8aff-875afa0543cb",
   "metadata": {},
   "source": [
    "# Python - Loading and plotting ADCP data\n",
    "\n",
    "\n",
    "**Aim:** To load and plot ADCP data from a *.000 binary file.\n",
    "\n",
    "**Data:** Download the data files from [https://www.dropbox.com/scl/fo/rcjbct5zhathfcadewfnz/AEYVgi25KAaVYtkYzv7sj2I?rlkey=46i0kvva0ydoi8ozf1w2hroqf&dl=0](https://www.dropbox.com/scl/fo/rcjbct5zhathfcadewfnz/AEYVgi25KAaVYtkYzv7sj2I?rlkey=46i0kvva0ydoi8ozf1w2hroqf&dl=0).  The largest of these is `10311.000`, which is 18mb.\n",
    "\n",
    "**Package:** You will need to install the `pycurrents_ADCP_processing` package from https://github.com/IOS-OSD-DPG/pycurrents_ADCP_processing.\n",
    "\n",
    "<!--If you prefer to do this without python, you can instead get data here: \n",
    "- [ICDC LAS](http://icdc.cen.uni-hamburg.de/las-int/getUI.do?dsid=id-13512db7081948&catid=DE25BCEB877C860DC89A1CFDB057A4B6&varid=air-id-13512db7081948&plot=XY_zoomable_image&view=xy&auto=true)\n",
    "- [PSL NOAA](https://psl.noaa.gov/data/gridded/data.ncep.reanalysis.html)\n",
    "\n",
    "For the purpose of this exercise, it's fine to use either source.-->\n",
    "\n",
    "**Directions:** Create an `*.ipynb` and 2 figures.\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019c0dd-b5e8-44cd-b840-7610db220bf5",
   "metadata": {},
   "source": [
    "## Create a notebook & load the data\n",
    "\n",
    "1. Create an `*.ipynb` containing the commands for this assignment, or copy this file and rename it, e.g., `computing-regoz-4-<Lastname>.ipynb`  \n",
    "\n",
    "2. Import necessary packages.\n",
    "\n",
    "\n",
    "    For example, `matplotlib` and `pandas` and `numpy` and `xarray`.  You may also need\n",
    "    ```{python}\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import xarray as xr\n",
    "    from datetime import datetime\n",
    "    ```\n",
    "    If you are missing any of these packages, please refer to [Resources: Python](../resource/python).\n",
    "\n",
    "    ```{note}\n",
    "    In this exercise, we will use the package [cartopy](https://scitools.org.uk/cartopy/docs/latest/getting_started/index.html) for the first time.  You will likely need to install this package on your computer (and in your environment, if you are using conda environments).\n",
    "    ```\n",
    "\n",
    "4. Download some data.\n",
    "\n",
    "    - Option 1: Simpler.  Get the data files from the Moodle.  Choose one of the folders (4 files each) called \"Heat flux files\".\n",
    "\n",
    "    - Option 2: Choose a year to work with: anything from 1948 to 2023.  Then navigate to each of the 4 components of surface heat fluxes from the NCEP reanalysis product, on the ICDC page [https://www.cen.uni-hamburg.de/en/icdc/data/atmosphere/reanalysis-atmosphere.html](https://www.cen.uni-hamburg.de/en/icdc/data/atmosphere/reanalysis-atmosphere.html).  Download **one of each file** for your chosen year.  Note that these files are about 30 mb each.\n",
    "  \n",
    "    ```{note}\n",
    "    This only works from the CEN/MPI network at UHH; that is, you can download files from one of the computers in the computer lab.  If you are working on the lab computers for this exercise, it will work fine.  If you're working on your personal computer, you will need ot transfer the files from the lab computer (where you download the data) to your personal computer.  A cloud service (e.g. the ownCloud system at UHH) can be used.  The files are large (>30mb each) which may mean they are too large to e-mail to yourself.\n",
    "    ```\n",
    "\n",
    "5. Make a basic exploration. How big are the data?  What are the coordinates?  Use `print()` or other commands you've learned in previous exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a841f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "from pycurrents_ADCP_processing import ADCP_processing_L0_L1, ADCP_IOS_Header_file\n",
    "from pycurrents_ADCP_processing import plot_westcoast_nc_LX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a44db0-ccfc-4bf5-87bf-0e09b9010344",
   "metadata": {},
   "source": [
    "### Downloading data\n",
    "\n",
    "- Put your data in the folder `data/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5736636d-c6cf-4e6d-9167-8451b9d40e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "file_path = 'data/'\n",
    "fname = 'adcp19nov2r.000'\n",
    "fname = '10311_adcp.0000'\n",
    "mname = 'template_ADCP_metadata.csv'\n",
    "f = file_path + fname\n",
    "file_meta = file_path + mname\n",
    "dest_dir = 'data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007faaf-35c7-4d50-a4cc-65b491017fbc",
   "metadata": {},
   "source": [
    "### Loading all variables into a single `dictionary`\n",
    "\n",
    "Python has a variable type called a \"dictionary\" which is used to store \"key - value\" pairs.  These are pairs like (x, y) is a pair, where the x (first member of the pair) is a \"key\" or the name you use to refer to something, and the y (second member of the pair) is the \"value\" or contents of the object named by the \"key\".\n",
    "\n",
    "```{seealso}\n",
    "Python dictionary: https://www.w3schools.com/python/python_dictionaries.asp\n",
    "```\n",
    "\n",
    "In the simple website example above, these are pairs of strings (the key is a string and the value is a string), or numbers (the key is a string and the values are numbers), or arrays.  In our case here, we can create a dictionary of xarray datasets (the \"key\" will be the name of the component of heat flux, one of \"lhtfl\", \"shtfl\", \"nswrs\" or \"nlwrs\", and the \"value\" or contents which we can call using the key is an xarray dataset).\n",
    "\n",
    "In your code above, replace the left side of the equation where you load the dataset (i.e., where you use the command `xr.open_dataset`) with\n",
    "```\n",
    "flux_components[fpre[i]] = xr.open_dataset(fname)\n",
    "```\n",
    "\n",
    "Once you have done this, you can check out the data within the dictionary using the following commands.\n",
    "\n",
    "The first one, `print(flux_components['lhtfl'].lhtfl.shape)` will tell you how big the dataset of latent heat flux is (x, y and z directions).\n",
    "\n",
    "The second looks more like an xarray dataset that you're familiar with (`print(flux_components['lhtfl']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c953b55d-5daf-4e38-bb03-f8e2a2a27848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddifying/micromamba/envs/seaocn_env/lib/python3.8/site-packages/pycurrents_ADCP_processing-1.0.1-py3.8.egg/pycurrents_ADCP_processing/ADCP_processing_L0_L1.py:453: UserWarning: Metadata item segment_end_indices in csv file has blank value\n",
      "  warnings.warn(f'Metadata item {row[0]} in csv file has blank value', UserWarning)\n",
      "/Users/eddifying/micromamba/envs/seaocn_env/lib/python3.8/site-packages/pycurrents_ADCP_processing-1.0.1-py3.8.egg/pycurrents_ADCP_processing/ADCP_processing_L0_L1.py:453: UserWarning: Metadata item segment_start_indices in csv file has blank value\n",
      "  warnings.warn(f'Metadata item {row[0]} in csv file has blank value', UserWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/eddifying/Library/Mobile Documents/com~apple~CloudDocs/Work/oldwork3/teaching/RegOz-UHH/coursebook-regoz/regoz-cb/computing/data/10311_adcp.0000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ncnames_L0 \u001b[38;5;241m=\u001b[39m \u001b[43mADCP_processing_L0_L1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnc_create_L0_L1\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/seaocn_env/lib/python3.8/site-packages/pycurrents_ADCP_processing-1.0.1-py3.8.egg/pycurrents_ADCP_processing/ADCP_processing_L0_L1.py:1015\u001b[0m, in \u001b[0;36mnc_create_L0_L1\u001b[0;34m(in_file, file_meta, dest_dir, level, time_file, verbose)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead in csv metadata file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;66;03m# ------------------------Read in data and start processing--------------------\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# Read in raw ADCP file and model type\u001b[39;00m\n\u001b[0;32m-> 1015\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mrdiraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrawfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead in raw data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Python/pycurrents/pycurrents/adcp/rdiraw.py:1692\u001b[0m, in \u001b[0;36mrawfile\u001b[0;34m(fname, sonar, trim, yearbase)\u001b[0m\n\u001b[1;32m   1690\u001b[0m sonar \u001b[38;5;241m=\u001b[39m Sonar(sonar)\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sonar\u001b[38;5;241m.\u001b[39misa(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpn\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileBBWHOS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msonar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myearbase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sonar\u001b[38;5;241m.\u001b[39misa(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yearbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Python/pycurrents/pycurrents/adcp/rdiraw.py:754\u001b[0m, in \u001b[0;36mFileBBWHOS.__init__\u001b[0;34m(self, fname, sonar, trim, yearbase)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ping_selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# The following calls self.open()\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m \u001b[43mFileBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msonar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtrim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myearbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearbase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_data_IDs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Python/pycurrents/pycurrents/adcp/rdiraw.py:590\u001b[0m, in \u001b[0;36mFileBase.__init__\u001b[0;34m(self, fname, inst, trim, yearbase, open)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trim \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopened:\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrim()\n",
      "File \u001b[0;32m~/Python/pycurrents/pycurrents/adcp/rdiraw.py:782\u001b[0m, in \u001b[0;36mFileBBWHOS.open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    775\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m    Open the file for reading.  There are no arguments.\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m    instrument rather than one that is being accreted in real time.\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m     \u001b[43mFileBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopened:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/pycurrents/pycurrents/adcp/rdiraw.py:648\u001b[0m, in \u001b[0;36mFileBase.open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobj)\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh_nprofs()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/eddifying/Library/Mobile Documents/com~apple~CloudDocs/Work/oldwork3/teaching/RegOz-UHH/coursebook-regoz/regoz-cb/computing/data/10311_adcp.0000'"
     ]
    }
   ],
   "source": [
    "ncnames_L0 = ADCP_processing_L0_L1.nc_create_L0_L1(in_file=f, file_meta=file_meta, dest_dir=dest_dir, level=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cfab9-dfad-4160-b6d1-bec7eb73ab28",
   "metadata": {},
   "source": [
    "### Merge into a single xarray dataset\n",
    "\n",
    "The dictionary of xarray datasets was kind of useful, but with xarray we don't need to bother using a dictionary to store the data.  Instead, we can use the command `xr.merge` to combine the similar datatypes (same coordinates, same dimensions, but different variables: latent, sensible heat flux, and shortwave and longwave radiation).  Take a look at this using `print()`.  What are the dimensions?  What are the coordinates?  What are the variables?  Compare this to your `print(flux_components['lhtfl'])` which contained only one of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0aec638-c3da-4100-af56-14eeab71bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/adcp19nov2r_L0.adcp.nc']\n",
      "<xarray.Dataset>\n",
      "Dimensions:                   (time: 84, distance: 80)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2015-11-19T11:58:27 ... 2...\n",
      "  * distance                  (distance) float64 0.73 0.98 1.23 ... 20.23 20.48\n",
      "Data variables: (12/29)\n",
      "    VEL_MAGNETIC_EAST         (distance, time) float32 ...\n",
      "    VEL_MAGNETIC_NORTH        (distance, time) float32 ...\n",
      "    LRZAAP01                  (distance, time) float32 ...\n",
      "    LERRAP01                  (distance, time) float32 ...\n",
      "    TNIHCE01                  (distance, time) float32 ...\n",
      "    TNIHCE02                  (distance, time) float32 ...\n",
      "    ...                        ...\n",
      "    filename                  object ...\n",
      "    instrument_serial_number  object ...\n",
      "    instrument_model          object ...\n",
      "    instrument_depth          float32 ...\n",
      "    water_depth               float32 ...\n",
      "    geographic_area           object ...\n",
      "Attributes: (12/76)\n",
      "    acknowledgement:             People\n",
      "    agency:                      NERC\n",
      "    anchor_drop_time:            2016-11-19 00:00:00 UTC\n",
      "    anchor_release_time:         2016-11-20 00:00:00 UTC\n",
      "    anchor_type:                 500\n",
      "    comment:                     Meta data is wrong\n",
      "    ...                          ...\n",
      "    geospatial_lat_units:        degrees_north\n",
      "    geospatial_lon_min:          -77.0\n",
      "    geospatial_lon_max:          -77.0\n",
      "    geospatial_lon_units:        degrees_east\n",
      "    geospatial_vertical_min:     5.73\n",
      "    geospatial_vertical_max:     25.48\n",
      "['VEL_MAGNETIC_EAST', 'VEL_MAGNETIC_NORTH', 'LRZAAP01', 'LERRAP01', 'TNIHCE01', 'TNIHCE02', 'TNIHCE03', 'TNIHCE04', 'CMAGZZ01', 'CMAGZZ02', 'CMAGZZ03', 'CMAGZZ04', 'PCGDAP00', 'PCGDAP02', 'PCGDAP03', 'PCGDAP04', 'latitude', 'longitude', 'PTCHGP01', 'HEADCM01', 'ROLLGP01', 'TEMPPR01', 'SVELCV01', 'filename', 'instrument_serial_number', 'instrument_model', 'instrument_depth', 'water_depth', 'geographic_area']\n"
     ]
    }
   ],
   "source": [
    "print(ncnames_L0)\n",
    "#filename = dest_dir + fname[0:-2] + '_L0' + 'adcp.nc'\n",
    "\n",
    "data1 = xr.open_dataset(ncnames_L0[0])\n",
    "print(data1)\n",
    "\n",
    "#print(data1.time.max())\n",
    "mykeys = list(data1.keys())\n",
    "print(mykeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6edce-6ce0-4077-abbd-88f7ae2a4d79",
   "metadata": {},
   "source": [
    "## Fig 1. Plot with `matplotlib`\n",
    "\n",
    "Now we'd like to take a look at the data for a single snapshot (a single time).  The example code below will choose the very first frame (where the time index is 0), and plot the latent heat flux.  Update the code in order to plot four fields (sensible, latent, shortwave and longwave).\n",
    "\n",
    "```{seealso}\n",
    "Information and examples using `matplotlib.pyplot.contourf()`: [https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contourf.html](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contourf.html).\n",
    "\n",
    "Scroll to the bottom of this page, and see a few examples of how to use `contourf()` and what the results can look like.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "549a898d-73a9-4d7a-a45f-433e7fc29eb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'LCEWAP01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ncfile \u001b[38;5;241m=\u001b[39m ncnames_L0[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m dest_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigures/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m output_files \u001b[38;5;241m=\u001b[39m \u001b[43mplot_westcoast_nc_LX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_westcoast_plots\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mncfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRegOz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/seaocn_env/lib/python3.8/site-packages/pycurrents_ADCP_processing-1.0.1-py3.8.egg/pycurrents_ADCP_processing/plot_westcoast_nc_LX.py:2486\u001b[0m, in \u001b[0;36mcreate_westcoast_plots\u001b[0;34m(ncfile, dest_dir, filter_type, along_angle, time_range, bin_range, single_bin_inds, single_bin_depths, colourmap_lim, override_resample, do_all_plots, do_diagnostic, do_pressure, do_single_bin_ne, do_ne, do_ac, do_quiver, do_single_rotary_spectra, do_tidal, do_profile_rotary_spectra, do_filter_ne, do_filter_ac)\u001b[0m\n\u001b[1;32m   2482\u001b[0m     output_file_list\u001b[38;5;241m.\u001b[39mappend(fname_diagnostic)\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# Limit data if limits are not input by user\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m time_lim, bin_depths_lim, ns_lim, ew_lim, time_range_idx, bin_range_idx \u001b[38;5;241m=\u001b[39m limit_data(\n\u001b[0;32m-> 2486\u001b[0m     ncdata, \u001b[43mncdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLCEWAP01\u001b[49m\u001b[38;5;241m.\u001b[39mdata, ncdata\u001b[38;5;241m.\u001b[39mLCNSAP01\u001b[38;5;241m.\u001b[39mdata, time_range, bin_range)\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;66;03m# Plot pressure PRESPR01 vs time\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_pressure \u001b[38;5;129;01mor\u001b[39;00m do_all_plots:\n",
      "File \u001b[0;32m~/micromamba/envs/seaocn_env/lib/python3.8/site-packages/xarray/core/common.py:278\u001b[0m, in \u001b[0;36mAttrAccessMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m source[name]\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'LCEWAP01'"
     ]
    }
   ],
   "source": [
    "# Plot the fields\n",
    "ncfile = ncnames_L0[0]\n",
    "dest_dir = 'figures/'\n",
    "output_files = plot_westcoast_nc_LX.create_westcoast_plots(\n",
    "    ncfile, dest_dir, \"RegOz\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822aada-1465-41d1-a855-035726956a69",
   "metadata": {},
   "source": [
    "## Making seasonal / annual average\n",
    "\n",
    "Now we're going to use some of the fancier features of the xarray data construction.  We'd like to make an average over all time (annual average) for this dataset.  Since we've stored the data all in a single `xarray` dataset, we can calculate the mean with one line of code.  \n",
    "\n",
    "```{python}\n",
    "ann_flux = all_flux.mean(dim='time', keep_attrs=True)\n",
    "```\n",
    "\n",
    "What happens if you don't include the `keep_attrs=True` option?  Try deleting it and see what changes.\n",
    "\n",
    "```{seealso}\n",
    "- Averaging `xarray` datasets all at once. [https://docs.xarray.dev/en/stable/generated/xarray.Dataset.mean.html](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.mean.html)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15581c8-9b52-4797-85a1-d7f083fb21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an average over a full year\n",
    "#ann_flux = all_flux.mean(dim='time', keep_attrs=True)\n",
    "#print(ann_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6e927-80e1-4fb8-a828-71f3ba7cfdda",
   "metadata": {},
   "source": [
    "## Fig 2. Update for annual averages\n",
    "\n",
    "Single-day snapshots of heat fluxes can be hard to read.  Let's repeat the plot above with the annual averages instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505f54b-6582-40e1-bcba-5d8f1c365d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fields\n",
    "# choose the index of the snapshot to show\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs[0,0].contourf(data1.lon, data1.lat, ann_flux.lhtfl[:,:], cmap='RdYlBu')\n",
    "axs[0,0].set_title('Latent heat flux')\n",
    "axs[0,0].set_ylabel('Latitude')\n",
    "\n",
    "# Cumbersome date time to string - Since we've done the annual average, we only need one year.\n",
    "d = data1.time[itime].dt.strftime('%Y').values\n",
    "fig.suptitle('NCEP Reanalysis \\n' + d)\n",
    "\n",
    "fig.savefig('fig2-heatflux-Lastname.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab293d-466e-45a7-a325-db84d669da9d",
   "metadata": {},
   "source": [
    "## Fig 3. Using `cartopy`\n",
    "\n",
    "What if you want to add some coastlines to your maps, and maybe switch up the map projection?  Here we'll use the `cartopy` package.\n",
    "\n",
    "```{seealso}\n",
    "How to use `cartopy` with `matplotlib`: [https://scitools.org.uk/cartopy/docs/latest/matplotlib/intro.html](https://scitools.org.uk/cartopy/docs/latest/matplotlib/intro.html)\n",
    "```\n",
    "\n",
    "The code below only partially works.  The y-axis labels are broken, and it currently plots the daily snapshot rather than the annual mean.  Try to update the plot to fix the y axis labels and to move the top row of figures closer to the bottom row.\n",
    "\n",
    "- Explore how to fix the labels on Cartopy maps: [https://scitools.org.uk/cartopy/docs/latest/gallery/gridlines_and_labels/tick_labels.html](https://scitools.org.uk/cartopy/docs/latest/gallery/gridlines_and_labels/tick_labels.html)\n",
    "\n",
    "- *Optional*: Try switching your map projection.  A map \"projection\" refers to how we render the near-spherical Earth on a flat piece of paper.  There are pros and cons of various map projections.  Things to ask yourself when choosing a projection:\n",
    "    - Are land-masses distorted (e.g. compared to spherical earth)?  E.g., is Greenland massive, or is your $x$ axis scaled strangely relative to your $y$ axis?\n",
    "    - Are lines of latitude/longitude straight?  (They don't need to be.)\n",
    "    - Will my map plotting choices distract from the data?\n",
    "\n",
    "    Aim to minimise distortions in the region where you want your viewer to focus their attention.\n",
    "\n",
    "    Available map projections with `cartopy`: [https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html](https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740385-616b-4fcd-b7f4-ba617bbb6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters for the map\n",
    "nrows=2\n",
    "ncols=2\n",
    "itime = 0\n",
    "myprojection = ccrs.AlbersEqualArea()\n",
    "myprojection = ccrs.Mercator()\n",
    "myprojection = ccrs.PlateCarree()\n",
    "\n",
    "# Initialise the map with the projection above\n",
    "fig, axs = plt.subplots(nrows=nrows,ncols=ncols,\n",
    "                        subplot_kw={'projection': myprojection},\n",
    "                        figsize=(11,8.5))\n",
    "\n",
    "# axs is a 2 dimensional array of `GeoAxes`.  \n",
    "# We will flatten it into a 1-D array.\n",
    "# This helps when plotting using a for-loop.\n",
    "axs=axs.flatten()\n",
    "\n",
    "# Loop through fluxes\n",
    "for i in range(len(fpre)):\n",
    "    # Select the flux to load\n",
    "    data1 = flux_components[fpre[i]]\n",
    "    map1 = data1[fpre[i]][itime,:,:]\n",
    "    axs[i].contourf(data1.lon, data1.lat, map1, cmap='RdYlBu', transform=cartopy.crs.PlateCarree())\n",
    "    axs[i].coastlines()               # plot some data on them\n",
    "    axs[i].set_title(fpre[i])                        # label it\n",
    "    axs[i].add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Longitude labels\n",
    "    axs[i].set_xticks(np.arange(-180,181,90), crs=cartopy.crs.PlateCarree())\n",
    "    lon_formatter = cticker.LongitudeFormatter()\n",
    "    axs[i].xaxis.set_major_formatter(lon_formatter)\n",
    "\n",
    "    # Latitude labels\n",
    "    axs[i].set_yticks(np.arange(-90,91,30), crs=ccrs.Mercator())\n",
    "\n",
    "fig.savefig('fig3-cartopy-lastname.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
